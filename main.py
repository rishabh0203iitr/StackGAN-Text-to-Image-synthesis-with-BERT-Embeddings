# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13SdE25cNr4QeB837TXPKMH87ysOFnDTV
"""

pip install torchfile

torch.cuda.get_device_name()

from google.colab import drive
drive.mount('/content/drive')

CUDA=True
TRAIN_FLAG=True
GPU_ID = '0'
IMSIZE=256
DATA_DIR='/content/drive/My Drive/102flowers'
TRAIN_BATCH_SIZE=32
WORKERS=4
STAGE=1

from __future__ import print_function
import torch.backends.cudnn as cudnn
import torch
import torchvision.transforms as transforms

import argparse
import os
import random
import sys
import pprint
import datetime
import dateutil
import dateutil.tz


# dir_path = (os.path.abspath(os.path.join(os.path.realpath(__file__), './.')))
# sys.path.append(dir_path)

from dataset import TextDataset

from utils import mkdir_p

manualSeed = random.randint(1, 10000)
random.seed(manualSeed)
torch.manual_seed(manualSeed)
if CUDA:
    torch.cuda.manual_seed_all(manualSeed)
now = datetime.datetime.now(dateutil.tz.tzlocal())
timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')
output_dir = '/content/output/%s_%s' % \
              ('102flowers', timestamp)

num_gpu = len(GPU_ID.split(','))
if TRAIN_FLAG:
    image_transform = transforms.Compose([
        transforms.RandomCrop(IMSIZE),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    dataset = TextDataset(DATA_DIR, 'jpg', imsize=IMSIZE, transform=image_transform)
    assert dataset
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=TRAIN_BATCH_SIZE * num_gpu,
        drop_last=True, shuffle=True, num_workers=int(1))

from trainer import GANTrainer
algo = GANTrainer(output_dir)
algo.train(dataloader, STAGE)

